{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate output stacked lstm example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from math import exp,sin,cos\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from keras.layers.core import Dense, Activation, Dense, Dropout, Flatten\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "r = 50\n",
    "a = 1000\n",
    "\n",
    "in_seq1 = []\n",
    "in_seq2 = []\n",
    "out_seq = []\n",
    "X1 = []\n",
    "X2 = []\n",
    "y1 = []\n",
    "y2 = []\n",
    "\n",
    "pi = 3.14159265359\n",
    "\n",
    "c = pi/180\n",
    "\n",
    "for i in range(2000):\n",
    "    in_seq1.append(r*(cos(i*c)))\n",
    "    in_seq2.append(r*(sin(i*c)))\n",
    "    out_seq.append(i*a)\n",
    "        \n",
    "in_seq1 = scale(in_seq1)\n",
    "in_seq2 = scale(in_seq2)\n",
    "out_seq = scale(out_seq)\n",
    "i = int(1000-(1000/3))\n",
    "\n",
    "#for i in range(1000):\n",
    "#   in_seq1.append(2*i)\n",
    "#   in_seq2.append(i)\n",
    "#   out_seq.append(i*3)\n",
    "\n",
    "    \n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = np.reshape(in_seq1,((len(in_seq1), 1)))\n",
    "in_seq2 = np.reshape(in_seq2,((len(in_seq2), 1)))\n",
    "out_seq = np.reshape(out_seq,((len(out_seq), 1)))\n",
    "\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps_in = 15\n",
    "n_steps_out = 2\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "X1 = X[0:667]\n",
    "X2 = X[667:1000]\n",
    "y1 = y[0:667]\n",
    "y2 = y[667:1000]\n",
    "n_features = X1.shape[2]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/rohaneshwar/majorproj/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/rohaneshwar/majorproj/lib/python2.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 30)                4080      \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 2, 30)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 2, 60)             21840     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 2, 60)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 2, 3)              183       \n",
      "=================================================================\n",
      "Total params: 26,103\n",
      "Trainable params: 26,103\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/rohaneshwar/majorproj/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 667 samples, validate on 333 samples\n",
      "Epoch 1/50\n",
      "667/667 [==============================] - 2s 3ms/step - loss: 1.0420 - val_loss: 0.5856\n",
      "Epoch 2/50\n",
      "667/667 [==============================] - 0s 656us/step - loss: 0.7235 - val_loss: 0.4695\n",
      "Epoch 3/50\n",
      "667/667 [==============================] - 0s 646us/step - loss: 0.4039 - val_loss: 0.3164\n",
      "Epoch 4/50\n",
      "667/667 [==============================] - 0s 660us/step - loss: 0.2131 - val_loss: 0.2234\n",
      "Epoch 5/50\n",
      "667/667 [==============================] - 0s 660us/step - loss: 0.1384 - val_loss: 0.1942\n",
      "Epoch 6/50\n",
      "667/667 [==============================] - 0s 657us/step - loss: 0.1033 - val_loss: 0.1556\n",
      "Epoch 7/50\n",
      "667/667 [==============================] - 0s 631us/step - loss: 0.0904 - val_loss: 0.1414\n",
      "Epoch 8/50\n",
      "667/667 [==============================] - 0s 681us/step - loss: 0.0830 - val_loss: 0.1328\n",
      "Epoch 9/50\n",
      "667/667 [==============================] - 0s 657us/step - loss: 0.0787 - val_loss: 0.1182\n",
      "Epoch 10/50\n",
      "667/667 [==============================] - 0s 673us/step - loss: 0.0741 - val_loss: 0.1000\n",
      "Epoch 11/50\n",
      "667/667 [==============================] - 0s 661us/step - loss: 0.0686 - val_loss: 0.0979\n",
      "Epoch 12/50\n",
      "667/667 [==============================] - 0s 676us/step - loss: 0.0687 - val_loss: 0.0943\n",
      "Epoch 13/50\n",
      "667/667 [==============================] - 0s 667us/step - loss: 0.0644 - val_loss: 0.0777\n",
      "Epoch 14/50\n",
      "667/667 [==============================] - 0s 698us/step - loss: 0.0597 - val_loss: 0.0713\n",
      "Epoch 15/50\n",
      "667/667 [==============================] - 1s 780us/step - loss: 0.0604 - val_loss: 0.0670\n",
      "Epoch 16/50\n",
      "667/667 [==============================] - 0s 648us/step - loss: 0.0577 - val_loss: 0.0683\n",
      "Epoch 17/50\n",
      "667/667 [==============================] - 0s 697us/step - loss: 0.0534 - val_loss: 0.0699\n",
      "Epoch 18/50\n",
      "667/667 [==============================] - 0s 595us/step - loss: 0.0534 - val_loss: 0.0616\n",
      "Epoch 19/50\n",
      "667/667 [==============================] - 0s 641us/step - loss: 0.0512 - val_loss: 0.0599\n",
      "Epoch 20/50\n",
      "667/667 [==============================] - 0s 658us/step - loss: 0.0499 - val_loss: 0.0554\n",
      "Epoch 21/50\n",
      "667/667 [==============================] - 0s 729us/step - loss: 0.0481 - val_loss: 0.0512\n",
      "Epoch 22/50\n",
      "667/667 [==============================] - 0s 692us/step - loss: 0.0487 - val_loss: 0.0575\n",
      "Epoch 23/50\n",
      "667/667 [==============================] - 0s 656us/step - loss: 0.0449 - val_loss: 0.0524\n",
      "Epoch 24/50\n",
      "667/667 [==============================] - 0s 659us/step - loss: 0.0419 - val_loss: 0.0576\n",
      "Epoch 25/50\n",
      "667/667 [==============================] - 0s 662us/step - loss: 0.0430 - val_loss: 0.0477\n",
      "Epoch 26/50\n",
      "667/667 [==============================] - 0s 665us/step - loss: 0.0419 - val_loss: 0.0460\n",
      "Epoch 27/50\n",
      "667/667 [==============================] - 0s 645us/step - loss: 0.0399 - val_loss: 0.0466\n",
      "Epoch 28/50\n",
      "667/667 [==============================] - 0s 686us/step - loss: 0.0396 - val_loss: 0.0456\n",
      "Epoch 29/50\n",
      "667/667 [==============================] - 0s 684us/step - loss: 0.0373 - val_loss: 0.0442\n",
      "Epoch 30/50\n",
      "667/667 [==============================] - 0s 684us/step - loss: 0.0375 - val_loss: 0.0486\n",
      "Epoch 31/50\n",
      "667/667 [==============================] - 0s 718us/step - loss: 0.0354 - val_loss: 0.0488\n",
      "Epoch 32/50\n",
      "667/667 [==============================] - 0s 668us/step - loss: 0.0360 - val_loss: 0.0472\n",
      "Epoch 33/50\n",
      "667/667 [==============================] - 0s 709us/step - loss: 0.0347 - val_loss: 0.0508\n",
      "Epoch 34/50\n",
      "667/667 [==============================] - 0s 647us/step - loss: 0.0358 - val_loss: 0.0501\n",
      "Epoch 35/50\n",
      "667/667 [==============================] - 0s 660us/step - loss: 0.0335 - val_loss: 0.0430\n",
      "Epoch 36/50\n",
      "667/667 [==============================] - 0s 621us/step - loss: 0.0335 - val_loss: 0.0467\n",
      "Epoch 37/50\n",
      "667/667 [==============================] - 0s 629us/step - loss: 0.0355 - val_loss: 0.0477\n",
      "Epoch 38/50\n",
      "667/667 [==============================] - 0s 658us/step - loss: 0.0350 - val_loss: 0.0545\n",
      "Epoch 39/50\n",
      "667/667 [==============================] - 0s 643us/step - loss: 0.0351 - val_loss: 0.0473\n",
      "Epoch 40/50\n",
      "667/667 [==============================] - 0s 643us/step - loss: 0.0343 - val_loss: 0.0505\n",
      "Epoch 41/50\n",
      "667/667 [==============================] - 0s 681us/step - loss: 0.0325 - val_loss: 0.0567\n",
      "Epoch 42/50\n",
      "667/667 [==============================] - 0s 643us/step - loss: 0.0325 - val_loss: 0.0534\n",
      "Epoch 43/50\n",
      "667/667 [==============================] - 0s 684us/step - loss: 0.0326 - val_loss: 0.0577\n",
      "Epoch 44/50\n",
      "667/667 [==============================] - 0s 747us/step - loss: 0.0319 - val_loss: 0.0545\n",
      "Epoch 45/50\n",
      "667/667 [==============================] - 0s 630us/step - loss: 0.0327 - val_loss: 0.0541\n",
      "Epoch 46/50\n",
      "667/667 [==============================] - 0s 661us/step - loss: 0.0320 - val_loss: 0.0520\n",
      "Epoch 47/50\n",
      "667/667 [==============================] - 0s 704us/step - loss: 0.0322 - val_loss: 0.0593\n",
      "Epoch 48/50\n",
      "667/667 [==============================] - 0s 659us/step - loss: 0.0333 - val_loss: 0.0511\n",
      "Epoch 49/50\n",
      "667/667 [==============================] - 0s 655us/step - loss: 0.0300 - val_loss: 0.0537\n",
      "Epoch 50/50\n",
      "667/667 [==============================] - 0s 703us/step - loss: 0.0291 - val_loss: 0.0565\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEWCAYAAABBvWFzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi40LCBodHRwOi8vbWF0cGxvdGxpYi5vcmcv7US4rQAAHj1JREFUeJzt3XucVXW9//HXWyDuyoCIXCQoPYmgAo5oRy08oKHl/QKlhZbyy5/+7H6i7KSZ/R5WZvw8WWZpkXkNI+moh9Qgs4syGBJ4A1F/DAgiCoKAin7OH+sLbaYZZpj57tmMvJ+Px37MunzXd32+e8N+z1pr7zWKCMzMzFpqt0oXYGZm7wwOFDMzy8KBYmZmWThQzMwsCweKmZll4UAxM7MsHChWcZJ+LumKJrZ9TtLYMtZylqTflav/cpJ0maRfpumBktZLatdY22bua6Gk0c3dfjv9zpZ0Xu5+rXW0r3QBZrlI+jlQGxFfa24fEXEzcHO2oiokIv4/0C1HX/U9rxExNEff9s7iIxTbZUjyL1BmZeRAsSZJp5q+JGm+pNck3SCpj6R7Ja2TdL+kqpL2J6bTImvSaYwhJetGSHo0bXc70KnOvj4iaV7a9s+SDmpCfZOAs4B/T6d6fltS95clzQdek9Re0mRJz6T9Py7plJJ+zpH0UMl8SPq0pEWpnmslqZ7995O0UVLPOuN8SVIHSftK+oOktWnZ7Q2M415JF9VZ9pikU9P0/5O0VNKrkuZKOqqBfgal2tun+cFp/+sk3QfsWaf9ryStSPU9KGloE57XsWm6o6QpkpanxxRJHdO60ZJqJX1B0ouSXpB0bv2v4j+NYTdJX5P0fNr2F5L2SOs6SfqlpNXpdZkjqU9ad46kJWmsz0o6qyn7swwiwg8/Gn0AzwF/BfoA/YEXgUeBERSB8Hvg0tT2X4DXgGOADsC/A4uBd6XH88Dn0rrTgTeBK9K2I1LfhwHtgIlp3x1L6hjbQI0/39JPnbrnAfsAndOyM4B+FL9QjU+19k3rzgEeKtk+gP8CegADgVXAuAb2/3vg/JL57wLXpelbgUvSPjsBRzbQxyeAP5XMHwCsKRn/2UAvitPVXwBWAJ3SusuAX6bpQan29mn+L8DVQEfgA8C6LW3T+k8C3dP6KcC8JjyvY9P05enfxl5Ab+DPwDfTutHA5tSmA3A8sAGoamD8s4HzSmpaDLyH4vTdr4Gb0rr/BfwW6JL+nRwC7A50BV4F3pfa9QWGVvr/z67y8BGK7Yj/jIiVEbEM+CPwcET8LSI2AdMpwgCKN+m7I+K+iHgTuAroDPwrcDjFG8uUiHgzIqYBc0r2MQn4cUQ8HBFvRcRU4PW0XXNdExFLI2IjQET8KiKWR8TbEXE7sAgYtZ3tr4yINVFcl5gFDG+g3S3ARwHSUcyEtAyK0Hw30C8iNkXEQ/V3wXRguKR3p/mzgF9HxOup9l9GxOqI2BwR36MIgPdtb/CSBgKHAv8REa9HxIMUb8ZbRcSNEbEu7ecy4OAtRwNNcBZweUS8GBGrgG8AHy9Z/2Za/2ZE3AOsb6zmkn6vjoglEbEe+AowIR11vUkRrPumfydzI+LVtN3bwDBJnSPihYhY2MRxWAs5UGxHrCyZ3ljP/JaLwP0ojkIAiIi3gaUURzb9gGURUXpX0udLpt8NfCGdxlgjaQ3F0UW/FtS9tHRG0idKTqmtAYZR5xRQHStKpjfQ8MXuO4H3S+pLcRTwNkXwQnGUJuCRdCrwk/V1EBHrgLspwgiKgNr6IQFJX5T0RDo1tQbYo5HaoXjuXomI10qWbX3OJbWTdGU6DfgqxdEHTei3tP/S1/B5tn29VkfE5pL57T2HjfXbnuIo+SZgJnBbOs32HUkd0hjHA58GXpB0t6T9mzgOayEHipXDcopgALb+tr4PsAx4Aehf5zrEwJLppcC3IqJHyaNLRNzahP02dOvsrcvTb/4/AS4CekVED2ABxZt9i0TEK8DvKN7QPgbctiU4I2JFRJwfEf0oTtf8UNK+DXR1K/BRSe+nOD02K9V+FEUwnUlxyqgHsLYJtb8AVEnqWrKs9Dn/GHASMJYioAal5Vv6beyW5Nu83qnv5Y1s0xT19bsZWJmOdr4REQdQHPl+hOJ0IRExMyKOoTjd9STF622twIFi5XAH8GFJYyR1oDjX/zrFufW/ULwpXJwuVp/KtqebfgJ8WtJhKnSV9GFJ3Zuw35UU59u3pyvFG+QqgHSBeNiODK4Rt1C8sZ3OP053IekMSQPS7Cuphrcb6OMeijfSy4Hb0xEeFNc4Nqfa20v6OsV1g+2KiOeBGuAbkt4l6UjghJIm3Slen9UU1yT+b50uGntebwW+Jqm3pD2BrwPN/o5LnX4/lz5Q0C3VdXtEbJZ0tKQDVXzP5lWKU2Bvq/igyEkpPF+nOL3W0PNsmTlQLLuIeIri4vF/Ai9RvHmdEBFvRMQbwKkUF79fpvht/tcl29YA5wM/oHjjXZzaNsUNwAHpVNZvGqjtceB7FMG2EjgQ+NOOjXC7ZgD7ASsi4rGS5YcCD0tan9p8JiKWNFDj6xTPyVhKQoniFM9/A09TnP7ZRJ3TedvxMYoPOrwMXAr8omTdL1J/y4DHKS6wl2rseb2CIrDmA3+n+LBGk76o2ogbKU5tPQg8SzHe/5PW7Q1MowiTJ4A/pLa7AZ+nOLp5GfggcEGGWqwJtO2pbDMzs+bxEYqZmWXhQDEzsywcKGZmloUDxczMstilbpa35557xqBBgypdhplZmzJ37tyXIqJ3Y+12qUAZNGgQNTU1lS7DzKxNkfR84618ysvMzDJxoJiZWRYOFDMzy2KXuoZiZu8cb775JrW1tWzatKnSpbxjdOrUiQEDBtChQ4dmbe9AMbM2qba2lu7duzNo0CD0z39E03ZQRLB69Wpqa2sZPHhws/rwKS8za5M2bdpEr169HCaZSKJXr14tOuJzoJhZm+Uwyaulz6cDxczMsnCgmJk1w5o1a/jhD3+4w9sdf/zxrFmzpgwVVZ4DxcysGRoKlM2bN293u3vuuYcePXqUq6yK8qe8zMyaYfLkyTzzzDMMHz6cDh060KlTJ6qqqnjyySd5+umnOfnkk1m6dCmbNm3iM5/5DJMmTQL+cQuo9evXc9xxx3HkkUfy5z//mf79+3PXXXfRuXPnCo+s+RwoZtbmfeO3C3l8+atZ+zyg3+5cesLQBtdfeeWVLFiwgHnz5jF79mw+/OEPs2DBgq0fub3xxhvp2bMnGzdu5NBDD+W0006jV69e2/SxaNEibr31Vn7yk59w5plncuedd3L22WdnHUdrcqCYmWUwatSobb6/cc011zB9+nQAli5dyqJFi/4pUAYPHszw4cMBOOSQQ3juuedard5ycKCYWZu3vSOJ1tK1a9et07Nnz+b+++/nL3/5C126dGH06NH1fr+jY8eOW6fbtWvHxo0bW6XWcvFFeTOzZujevTvr1q2rd93atWupqqqiS5cuPPnkk/z1r39t5eoqw0coZmbN0KtXL4444giGDRtG586d6dOnz9Z148aN47rrrmPIkCG8733v4/DDD69gpa1HEVHpGlpNdXV1+A9smb0zPPHEEwwZMqTSZbzj1Pe8SpobEdWNbetTXmZmloUDxczMsnCgmJlZFg4UMzPLwoFiZmZZOFDMzCwLB4qZWSvo1q0bAMuXL+f000+vt83o0aNp7KsNU6ZMYcOGDVvnd6bb4TtQzMxaUb9+/Zg2bVqzt68bKDvT7fArGiiSxkl6StJiSZPrWd9R0u1p/cOSBtVZP1DSeklfbK2azcyguH39tddeu3X+sssu44orrmDMmDGMHDmSAw88kLvuuuuftnvuuecYNmwYABs3bmTChAkMGTKEU045ZZt7eV1wwQVUV1czdOhQLr30UqC44eTy5cs5+uijOfroo4HidvgvvfQSAFdffTXDhg1j2LBhTJkyZev+hgwZwvnnn8/QoUM59thjy3bPsIrdekVSO+Ba4BigFpgjaUZEPF7S7FPAKxGxr6QJwLeB8SXrrwbuba2azWwnde9kWPH3vH3ufSAcd2WDq8ePH89nP/tZLrzwQgDuuOMOZs6cycUXX8zuu+/OSy+9xOGHH86JJ57Y4N9q/9GPfkSXLl144oknmD9/PiNHjty67lvf+hY9e/bkrbfeYsyYMcyfP5+LL76Yq6++mlmzZrHnnntu09fcuXP52c9+xsMPP0xEcNhhh/HBD36QqqqqVrtNfiWPUEYBiyNiSUS8AdwGnFSnzUnA1DQ9DRij9MpIOhl4FljYSvWamW01YsQIXnzxRZYvX85jjz1GVVUVe++9N1/96lc56KCDGDt2LMuWLWPlypUN9vHggw9ufWM/6KCDOOigg7auu+OOOxg5ciQjRoxg4cKFPP744w11A8BDDz3EKaecQteuXenWrRunnnoqf/zjH4HWu01+JW8O2R9YWjJfCxzWUJuI2CxpLdBL0ibgyxRHN9s93SVpEjAJYODAgXkqN7Ody3aOJMrpjDPOYNq0aaxYsYLx48dz8803s2rVKubOnUuHDh0YNGhQvbetb8yzzz7LVVddxZw5c6iqquKcc85pVj9btNZt8tvqRfnLgO9HxPrGGkbE9RFRHRHVvXv3Ln9lZrbLGD9+PLfddhvTpk3jjDPOYO3atey111506NCBWbNm8fzzz293+w984APccsstACxYsID58+cD8Oqrr9K1a1f22GMPVq5cyb33/uPMfkO3zT/qqKP4zW9+w4YNG3jttdeYPn06Rx11VMbRNq6SRyjLgH1K5gekZfW1qZXUHtgDWE1xJHO6pO8APYC3JW2KiB+Uv2wzs8LQoUNZt24d/fv3p2/fvpx11lmccMIJHHjggVRXV7P//vtvd/sLLriAc889lyFDhjBkyBAOOeQQAA4++GBGjBjB/vvvzz777MMRRxyxdZtJkyYxbtw4+vXrx6xZs7YuHzlyJOeccw6jRo0C4LzzzmPEiBGt+lcgK3b7+hQQTwNjKIJjDvCxiFhY0uZC4MCI+HS6KH9qRJxZp5/LgPURcVVj+/Tt683eOXz7+vJoye3rK3aEkq6JXATMBNoBN0bEQkmXAzURMQO4AbhJ0mLgZWBCpeo1M7Ptq+hfbIyIe4B76iz7esn0JuCMRvq4rCzFmZnZDmmrF+XNzNiV/uJsa2jp8+lAMbM2qVOnTqxevdqhkklEsHr1ajp16tTsPip6ysvMrLkGDBhAbW0tq1atqnQp7xidOnViwIABzd7egWJmbVKHDh0YPHhwpcuwEj7lZWZmWThQzMwsCweKmZll4UAxM7MsHChmZpaFA8XMzLJwoJiZWRYOFDMzy8KBYmZmWThQzMwsCweKmZll4UAxM7MsHChmZpaFA8XMzLJwoJiZWRYOFDMzy8KBYmZmWThQzMwsCweKmZll4UAxM7MsHChmZpaFA8XMzLJwoJiZWRYOFDMzy8KBYmZmWThQzMwsi4oGiqRxkp6StFjS5HrWd5R0e1r/sKRBafkxkuZK+nv6+W+tXbuZmW2rYoEiqR1wLXAccADwUUkH1Gn2KeCViNgX+D7w7bT8JeCEiDgQmAjc1DpVm5lZQyp5hDIKWBwRSyLiDeA24KQ6bU4CpqbpacAYSYqIv0XE8rR8IdBZUsdWqdrMzOpVyUDpDywtma9Ny+ptExGbgbVArzptTgMejYjXy1SnmZk1QftKF9ASkoZSnAY7djttJgGTAAYOHNhKlZmZ7XoqeYSyDNinZH5AWlZvG0ntgT2A1Wl+ADAd+EREPNPQTiLi+oiojojq3r17ZyzfzMxKVTJQ5gD7SRos6V3ABGBGnTYzKC66A5wO/D4iQlIP4G5gckT8qdUqNjOzBlUsUNI1kYuAmcATwB0RsVDS5ZJOTM1uAHpJWgx8Htjy0eKLgH2Br0ualx57tfIQzMyshCKi0jW0murq6qipqal0GWZmbYqkuRFR3Vg7f1PezMyycKCYmVkWDhQzM8vCgWJmZlk4UMzMLAsHipmZZeFAMTOzLBwoZmaWhQPFzMyycKCYmVkWDhQzM8vCgWJmZlk4UMzMLAsHipmZZeFAMTOzLBwoZmaWhQPFzMyycKCYmVkWDhQzM8vCgWJmZlk4UMzMLAsHipmZZeFAMTOzLBwoZmaWhQPFzMyycKCYmVkWDhQzM8vCgWJmZlk0KVAkfUbS7ircIOlRSceWuzgzM2s7mnqE8smIeBU4FqgCPg5cWbaqzMyszWlqoCj9PB64KSIWliwzMzNrcqDMlfQ7ikCZKak78HZLdy5pnKSnJC2WNLme9R0l3Z7WPyxpUMm6r6TlT0n6UEtrMTOzlmnfxHafAoYDSyJig6SewLkt2bGkdsC1wDFALTBH0oyIeLzOfl+JiH0lTQC+DYyXdAAwARgK9APul/QvEfFWS2oyM7Pma+oRyvuBpyJijaSzga8Ba1u471HA4ohYEhFvALcBJ9VpcxIwNU1PA8ZIUlp+W0S8HhHPAotTf2ZmViFNDZQfARskHQx8AXgG+EUL990fWFoyX5uW1dsmIjZThFivJm4LgKRJkmok1axataqFJZuZWUOaGiibIyIojgx+EBHXAt3LV1Y+EXF9RFRHRHXv3r0rXY6Z2TtWUwNlnaSvUHxc+G5JuwEdWrjvZcA+JfMD0rJ620hqD+wBrG7itmZm1oqaGijjgdcpvo+yguIN/Lst3PccYD9JgyW9i+Ii+4w6bWYAE9P06cDv05HSDGBC+hTYYGA/4JEW1mNmZi3QpE95RcQKSTcDh0r6CPBIRLToGkpEbJZ0ETATaAfcGBELJV0O1ETEDOAG4CZJi4GXKUKH1O4O4HFgM3ChP+FlZlZZKn7hb6SRdCbFEclsii80HgV8KSKmlbW6zKqrq6OmpqbSZZiZtSmS5kZEdWPtmvo9lEuAQyPixdR5b+B+io/ympmZNfkaym5bwiRZvQPbmpnZLqCpRyj/LWkmcGuaHw/cU56SzMysLWrqRfkvSToNOCItuj4ippevLDMza2uaeoRCRNwJ3FnGWszMrA3bbqBIWgfU9zEwARERu5elKjMza3O2GygR0SZur2JmZpXnT2qZmVkWDhQzM8vCgWJmZlk4UMzMLAsHipmZZeFAMTOzLBwoZmaWhQPFzMyycKCYmVkWDhQzM8vCgWJmZlk4UMzMLAsHipmZZeFAMTOzLBwoZmaWhQPFzMyycKCYmVkWDhQzM8vCgWJmZlk4UMzMLAsHipmZZeFAMTOzLBwoZmaWRUUCRVJPSfdJWpR+VjXQbmJqs0jSxLSsi6S7JT0paaGkK1u3ejMzq0+ljlAmAw9ExH7AA2l+G5J6ApcChwGjgEtLgueqiNgfGAEcIem41inbzMwaUqlAOQmYmqanAifX0+ZDwH0R8XJEvALcB4yLiA0RMQsgIt4AHgUGtELNZma2HZUKlD4R8UKaXgH0qadNf2BpyXxtWraVpB7ACRRHOWZmVkHty9WxpPuBvetZdUnpTESEpGhG/+2BW4FrImLJdtpNAiYBDBw4cEd3Y2ZmTVS2QImIsQ2tk7RSUt+IeEFSX+DFepotA0aXzA8AZpfMXw8siogpjdRxfWpLdXX1DgeXmZk1TaVOec0AJqbpicBd9bSZCRwrqSpdjD82LUPSFcAewGdboVYzM2uCSgXKlcAxkhYBY9M8kqol/RQgIl4GvgnMSY/LI+JlSQMoTpsdADwqaZ6k8yoxCDMz+wdF7Dpngaqrq6OmpqbSZZiZtSmS5kZEdWPt/E15MzPLwoFiZmZZOFDMzCwLB4qZmWXhQDEzsywcKGZmloUDxczMsnCgmJlZFg4UMzPLwoFiZmZZOFDMzCwLB4qZmWXhQDEzsywcKGZmloUDxczMsnCgmJlZFg4UMzPLwoFiZmZZOFDMzCwLB4qZmWXhQDEzsywcKGZmloUDxczMsnCgmJlZFg4UMzPLwoFiZmZZOFDMzCwLB4qZmWXhQDEzsywcKGZmloUDxczMsqhIoEjqKek+SYvSz6oG2k1MbRZJmljP+hmSFpS/YjMza0yljlAmAw9ExH7AA2l+G5J6ApcChwGjgEtLg0fSqcD61inXzMwaU6lAOQmYmqanAifX0+ZDwH0R8XJEvALcB4wDkNQN+DxwRSvUamZmTVCpQOkTES+k6RVAn3ra9AeWlszXpmUA3wS+B2xobEeSJkmqkVSzatWqFpRsZmbb075cHUu6H9i7nlWXlM5EREiKHeh3OPDeiPicpEGNtY+I64HrAaqrq5u8HzMz2zFlC5SIGNvQOkkrJfWNiBck9QVerKfZMmB0yfwAYDbwfqBa0nMU9e8laXZEjMbMzCqmUqe8ZgBbPrU1EbirnjYzgWMlVaWL8ccCMyPiRxHRLyIGAUcCTztMzMwqr1KBciVwjKRFwNg0j6RqST8FiIiXKa6VzEmPy9MyMzPbCSli17msUF1dHTU1NZUuw8ysTZE0NyKqG2vnb8qbmVkWDhQzM8vCgWJmZlk4UMzMLAsHipmZZeFAMTOzLBwoZmaWhQPFzMyycKCYmVkWDhQzM8vCgWJmZlk4UMzMLAsHipmZZeFAMTOzLBwoZmaWhQPFzMyycKCYmVkWDhQzM8vCgWJmZlk4UMzMLAsHipmZZeFAMTOzLBwoZmaWhQPFzMyyUERUuoZWI2kV8Hyl69hBewIvVbqIVuYx7xo85rbj3RHRu7FGu1SgtEWSaiKiutJ1tCaPedfgMb/z+JSXmZll4UAxM7MsHCg7v+srXUAFeMy7Bo/5HcbXUMzMLAsfoZiZWRYOFDMzy8KBshOQ1FPSfZIWpZ9VDbSbmNoskjSxnvUzJC0of8Ut15IxS+oi6W5JT0paKOnK1q1+x0gaJ+kpSYslTa5nfUdJt6f1D0saVLLuK2n5U5I+1Jp1t0RzxyzpGElzJf09/fy31q69OVryGqf1AyWtl/TF1qq5LCLCjwo/gO8Ak9P0ZODb9bTpCSxJP6vSdFXJ+lOBW4AFlR5PuccMdAGOTm3eBfwROK7SY2pgnO2AZ4D3pFofAw6o0+Z/A9el6QnA7Wn6gNS+IzA49dOu0mMq85hHAP3S9DBgWaXHU87xlqyfBvwK+GKlx9OSh49Qdg4nAVPT9FTg5HrafAi4LyJejohXgPuAcQCSugGfB65ohVpzafaYI2JDRMwCiIg3gEeBAa1Qc3OMAhZHxJJU620UYy9V+lxMA8ZIUlp+W0S8HhHPAotTfzu7Zo85Iv4WEcvT8oVAZ0kdW6Xq5mvJa4ykk4FnKcbbpjlQdg59IuKFNL0C6FNPm/7A0pL52rQM4JvA94ANZaswv5aOGQBJPYATgAfKUWQGjY6htE1EbAbWAr2auO3OqCVjLnUa8GhEvF6mOnNp9njTL4NfBr7RCnWWXftKF7CrkHQ/sHc9qy4pnYmIkNTkz3JLGg68NyI+V/e8bKWVa8wl/bcHbgWuiYglzavSdkaShgLfBo6tdC1ldhnw/YhYnw5Y2jQHSiuJiLENrZO0UlLfiHhBUl/gxXqaLQNGl8wPAGYD7weqJT1H8XruJWl2RIymwso45i2uBxZFxJQM5ZbLMmCfkvkBaVl9bWpTSO4BrG7itjujlowZSQOA6cAnIuKZ8pfbYi0Z72HA6ZK+A/QA3pa0KSJ+UP6yy6DSF3H8CIDvsu0F6u/U06YnxXnWqvR4FuhZp80g2s5F+RaNmeJ60Z3AbpUeSyPjbE/xYYLB/OOC7dA6bS5k2wu2d6TpoWx7UX4JbeOifEvG3CO1P7XS42iN8dZpcxlt/KJ8xQvwI6A4d/wAsAi4v+RNsxr4aUm7T1JcmF0MnFtPP20pUJo9ZorfAAN4ApiXHudVekzbGevxwNMUnwS6JC27HDgxTXei+ITPYuAR4D0l216StnuKnfSTbDnHDHwNeK3kdZ0H7FXp8ZTzNS7po80Him+9YmZmWfhTXmZmloUDxczMsnCgmJlZFg4UMzPLwoFiZmZZOFDM2gBJoyX9V6XrMNseB4qZmWXhQDHLSNLZkh6RNE/SjyW1S3/n4vvpb7c8IKl3ajtc0l8lzZc0fcvfhJG0r6T7JT0m6VFJ703dd5M0Lf0dmJu33K3WbGfhQDHLRNIQYDxwREQMB94CzgK6AjURMRT4A3Bp2uQXwJcj4iDg7yXLbwaujYiDgX8FttyVeQTwWYq/k/Ie4IiyD8psB/jmkGb5jAEOAeakg4fOFDe9fBu4PbX5JfBrSXsAPSLiD2n5VOBXkroD/SNiOkBEbAJI/T0SEbVpfh7FrXYeKv+wzJrGgWKWj4CpEfGVbRZK/1GnXXPvd1T6d0Hewv9/bSfjU15m+TxAcSvyvQAk9ZT0bor/Z6enNh8DHoqItcArko5Kyz8O/CEi1lHc4vzk1EdHSV1adRRmzeTfcMwyiYjHJX0N+J2k3YA3KW5b/howKq17keI6C8BE4LoUGEuAc9PyjwM/lnR56uOMVhyGWbP5bsNmZSZpfUR0q3QdZuXmU15mZpaFj1DMzCwLH6GYmVkWDhQzM8vCgWJmZlk4UMzMLAsHipmZZfE/zKssPMQCUMUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(30, activation='relu', input_shape=(n_steps_in, n_features)))\n",
    "model.add(RepeatVector(n_steps_out))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(60, activation='relu', return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(TimeDistributed(Dense(n_features)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "history = model.fit(X1, y1, epochs=50, verbose=1,validation_data=(X2, y2))\n",
    "pyplot.plot(history.history['loss'][50:])\n",
    "pyplot.plot(history.history['val_loss'][50:])\n",
    "pyplot.title('model train vs validation loss')\n",
    "pyplot.ylabel('loss')\n",
    "pyplot.xlabel('epoch')\n",
    "pyplot.legend(['train', 'validation'], loc='upper right')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# demonstrate prediction\n",
    "#x_input = array([[70,75,145], [80,85,165], [90,95,185]])\n",
    "x_input = array([[50.0000000, 0.0000000000, 0.00000000],\n",
    " [49.9923848, 8.72620322, 1000.00000],\n",
    " [49.9695414, 1.74497484, 2000.00000],\n",
    " [49.9314767, 2.61679781, 3000.00000],\n",
    " [49.8782025, 3.48782369, 4000.00000],\n",
    " [49.8097349, 4.35778714, 5000.00000],\n",
    " [49.7260948, 5.22642316, 6000.00000],\n",
    " [49.6273076, 6.09346717, 7000.00000],\n",
    " [49.5134034, 6.95865505, 8000.00000],\n",
    " [49.3844170, 7.82172325, 9000.00000],\n",
    " [49.2403877, 8.68240888, 1000.00000],\n",
    " [49.0813592, 9.54044977, 1100.00000],\n",
    " [48.9073800, 1.03955845, 1200.00000],\n",
    " [48.7185032, 1.12475527, 1300.00000],\n",
    " [48.5147863, 1.20960948, 1400.00000]])\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "yhat = []\n",
    "yhat = model.predict(x_input, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
